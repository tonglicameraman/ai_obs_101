package com.dynatrace.ca.se.demo.aiobs.openllmetry;

import dev.langchain4j.data.message.AiMessage;
import dev.langchain4j.data.message.ChatMessage;
import dev.langchain4j.model.chat.listener.ChatModelErrorContext;
import dev.langchain4j.model.chat.listener.ChatModelListener;
import dev.langchain4j.model.chat.listener.ChatModelRequestContext;
import dev.langchain4j.model.chat.listener.ChatModelResponseContext;
import dev.langchain4j.model.chat.request.ChatRequest;
import dev.langchain4j.model.chat.request.ChatRequestParameters;
import dev.langchain4j.model.chat.response.ChatResponse;
import dev.langchain4j.model.chat.response.ChatResponseMetadata;
import dev.langchain4j.model.openai.OpenAiChatResponseMetadata;
import dev.langchain4j.model.output.TokenUsage;
import io.opentelemetry.api.trace.Span;
import io.opentelemetry.api.trace.StatusCode;
import lombok.val;
import org.springframework.stereotype.Component;

import java.util.List;

// https://docs.dynatrace.com/docs/analyze-explore-automate/dynatrace-for-ai-observability/models-and-platforms/openai
@Component
public class OpenLLMetryOpenAiListener implements ChatModelListener {
    //gen_ai.completion.0.content    //string    //The full response received from the GenAI model.
    public static final String COMPLETION_CONTENT_KEY = "gen_ai.completion.0.content";

    //gen_ai.completion.0.content_filter_results    //string    //The filter results of the response received from the GenAI model.
    public static final String COMPLETION_CONTENT_FILTER_KEY = "gen_ai.completion.0.content_filter_results";

    //gen_ai.completion.0.finish_reason    //string    //The reason the GenAI model stopped producing tokens.
    public static final String FINISH_REASON_KEY = "gen_ai.completion.0.finish_reason";

    //gen_ai.completion.0.role    //string    //The role used by the GenAI model.
    public static final String ROLE_KEY = "gen_ai.completion.0.role";

    //gen_ai.openai.api_base    //string    //GenAI server address.
    public static final String API_BASE_KEY = "gen_ai.openai.api_base";

    //gen_ai.openai.api_version    //string    //GenAI API version.
    public static final String API_VERSION_KEY = "gen_ai.openai.api_version";

    //gen_ai.openai.system_fingerprint    //string    //The fingerprint of the response generated by the GenAI model.
    public static final String SYSTEM_FINGERPRINT_KEY = "gen_ai.openai.system_fingerprint";

    //gen_ai.prompt.0.content    //string    //The full prompt sent to the GenAI model.
    public static final String PROMPT_CONTENT_KEY = "gen_ai.prompt.0.content";

    //gen_ai.prompt.0.role    //string    //The role setting for the GenAI request.
    public static final String PROMPT_ROLE_KEY = "gen_ai.prompt.0.role";

    //gen_ai.prompt.prompt_filter_results    //string    //The filter results of the prompt sent to the GenAI model.
    public static final String PROMPT_FILTER_KEY = "gen_ai.prompt.prompt_filter_results";

    //gen_ai.request.max_tokens    //integer    //The maximum number of tokens the model generates for a request.
    public static final String REQUEST_MAX_TOKENS_KEY = "gen_ai.request.max_tokens";

    //gen_ai.request.model    //string    //The name of the GenAI model a request is being made to.
    public static final String REQUEST_MODEL_KEY = "gen_ai.request.model";

    //gen_ai.request.temperature    //double    //The temperature setting for the GenAI request.
    public static final String REQUEST_TEMPERATURE_KEY = "gen_ai.request.temperature";

    //gen_ai.request.top_p    //double    //The top_p sampling setting for the GenAI request.
    public static final String REQUEST_TOPP_KEY = "gen_ai.request.top_p";

    //gen_ai.response.model    //string    //The name of the model that generated the response.
    public static final String RESPONSE_MODEL_KEY = "gen_ai.response.model";

    //gen_ai.system    //string    //The GenAI product as identified by the client or server instrumentation.
    public static final String SYSTEM_KEY = "gen_ai.system";

    //gen_ai.usage.completion_tokens    //integer    //The number of tokens used in the GenAI response (completion).
    public static final String COMPLETION_TOKENS_KEY = "gen_ai.usage.completion_tokens";

    //gen_ai.usage.prompt_tokens    //integer    //The number of tokens used in the GenAI input (prompt).
    public static final String PROMPT_TOKENS_KEY = "gen_ai.usage.prompt_tokens";

    //llm.request.type //string    //The type of the operation being performed.
    public static final String REQUEST_TYPE_KEY = "llm.request.type";

    @Override
    public void onRequest(ChatModelRequestContext requestContext) {
        Span span = Span.current();

        if (span.isRecording()) {
            ChatRequest chatRequest = requestContext.chatRequest();

            List<ChatMessage> messages = chatRequest.messages();
            if (!messages.isEmpty()) {
                val message = messages.get(0);

                fillIfDefined(span, PROMPT_ROLE_KEY, message.type().name());
            }

            ChatRequestParameters parameters = chatRequest.parameters();
            fillIfDefined(span, REQUEST_MODEL_KEY, parameters.modelName());
            fillIfDefined(span, REQUEST_TEMPERATURE_KEY, parameters.temperature());
            fillIfDefined(span, REQUEST_TOPP_KEY, parameters.topP());
            //System.out.println(parameters.topK());
//            System.out.println(parameters.frequencyPenalty());
//            System.out.println(parameters.presencePenalty());
            fillIfDefined(span, REQUEST_MAX_TOKENS_KEY, parameters.maxOutputTokens());
//            System.out.println(parameters.maxOutputTokens());
//            System.out.println(parameters.stopSequences());
//            System.out.println(parameters.toolSpecifications());
//            System.out.println(parameters.toolChoice());
//            System.out.println(parameters.responseFormat());

//            if (parameters instanceof OpenAiChatRequestParameters openAiParameters) {
//                System.out.println(openAiParameters.maxCompletionTokens());
//                System.out.println(openAiParameters.logitBias());
//                System.out.println(openAiParameters.parallelToolCalls());
//                System.out.println(openAiParameters.seed());
//                System.out.println(openAiParameters.user());
//                System.out.println(openAiParameters.store());
//                System.out.println(openAiParameters.metadata());
//                System.out.println(openAiParameters.serviceTier());
//                System.out.println(openAiParameters.reasoningEffort());
//            }

            fillIfDefined(span, REQUEST_MODEL_KEY, requestContext.modelProvider());

//            Map<Object, Object> attributes = requestContext.attributes();
//            attributes.put("my-attribute", "my-value");
        }
    }

    @Override
    public void onResponse(ChatModelResponseContext responseContext) {
        Span span = Span.current();

        if (span.isRecording()) {
            ChatResponse chatResponse = responseContext.chatResponse();

            AiMessage aiMessage = chatResponse.aiMessage();
            fillIfDefined(span, COMPLETION_CONTENT_KEY, aiMessage.text());

            ChatResponseMetadata metadata = chatResponse.metadata();
//            System.out.println(metadata.id());
            fillIfDefined(span, RESPONSE_MODEL_KEY, metadata.modelName());
            fillIfDefined(span, FINISH_REASON_KEY, metadata.finishReason());

            if (metadata instanceof OpenAiChatResponseMetadata openAiMetadata) {
//                System.out.println(openAiMetadata.created());
//                System.out.println(openAiMetadata.serviceTier());
                fillIfDefined(span, SYSTEM_FINGERPRINT_KEY, openAiMetadata.systemFingerprint());
            }

            TokenUsage tokenUsage = metadata.tokenUsage();
            fillIfDefined(span, PROMPT_TOKENS_KEY, tokenUsage.inputTokenCount());
            fillIfDefined(span, COMPLETION_TOKENS_KEY, tokenUsage.outputTokenCount());
//            System.out.println(tokenUsage.totalTokenCount());
//            if (tokenUsage instanceof OpenAiTokenUsage openAiTokenUsage) {
//                System.out.println(openAiTokenUsage.inputTokensDetails().cachedTokens());
//                System.out.println(openAiTokenUsage.outputTokensDetails().reasoningTokens());
//            }

//            ChatRequest chatRequest = responseContext.chatRequest();
//            System.out.println(chatRequest);

            fillIfDefined(span, RESPONSE_MODEL_KEY, responseContext.modelProvider().name());

//            Map<Object, Object> attributes = responseContext.attributes();
//            System.out.println(attributes.get("my-attribute"));
        }
    }

    @Override
    public void onError(ChatModelErrorContext errorContext) {
        Span span = Span.current();

        if (span.isRecording()) {
            span.setStatus(StatusCode.ERROR);
            span.recordException(errorContext.error());
            fillIfDefined(span, RESPONSE_MODEL_KEY, errorContext.modelProvider().name());
        }
    }

    public static <T> void fillIfDefined(Span span, String key, T value) {
        if (value != null) {
            if (value instanceof Long) {
                span.setAttribute(key, (Long) value);
            } else if (value instanceof Double) {
                span.setAttribute(key, (Double) value);
            } else if (value instanceof Boolean) {
                span.setAttribute(key, (Boolean) value);
            } else {
                span.setAttribute(key, value.toString());
            }
        }
    }
}
